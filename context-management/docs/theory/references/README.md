# SMoC Reference Library

> **82 academic works** forming the intellectual foundation of the Standard Model of Code
> **13,882 extracted figures** with structured metadata
> **~5.4M tokens** of LLM-ready content
> **Last Updated:** 2026-01-27

---

## What This Is

A structured academic reference library documenting every intellectual source that informs the Standard Model of Code. Each reference has been:

1. **Downloaded** as PDF (free sources only, $0 spent)
2. **Text-extracted** to enhanced TXT with SMoC relevance markers
3. **Image-extracted** with metadata (figures, diagrams, equations)
4. **Metadata-stubbed** following `library_schema.json`
5. **Cataloged** in searchable master index

---

## Quick Start

```bash
# View the catalog
cat index/catalog.json | jq '.total_refs, .total_images, .total_tokens_estimate'

# Read a reference (with placeholders for SMoC analysis)
cat txt/REF-001.txt

# View its metadata
cat metadata/REF-001.json | jq .

# See extracted figures
ls images/REF-001/
cat images/REF-001/metadata.json | jq .

# List all references by author
cat index/catalog.json | jq '.by_author | keys'
```

---

## Directory Structure

```
references/
├── pdf/              82 source PDFs (322 MB)
├── txt/              65 enhanced TXT files (~26 MB)
├── images/           65 folders, 13,882 figures
│   └── REF-XXX/
│       ├── fig_page_001_000.png
│       └── metadata.json
├── metadata/         65 JSON files (stubs awaiting LLM analysis)
│   └── REF-XXX.json
├── index/
│   └── catalog.json  Master searchable index
├── md/               82 basic markdown (legacy, kept for reference)
├── library_schema.json          Metadata schema
├── holon_hierarchy_schema.json  Holon-specific schema
├── process_library.py           Extraction pipeline
├── analyze_ref.py               LLM analysis prompt generator
└── VALIDATION_AND_INTEGRATION_PLAN.md
```

---

## File Naming Convention

- **PDFs:** `REF-XXX_Author_Year_ShortTitle.pdf` or `AUTHOR_Year_Title.pdf`
- **TXT:** `REF-XXX.txt` (one per author if multiple works)
- **Images:** `images/REF-XXX/fig_page_NNN_MMM.{png|jpg}`
- **Metadata:** `metadata/REF-XXX.json`

---

## Current Status

| Phase | Status | Count |
|-------|--------|-------|
| **Phase 1: Extraction** | ✅ COMPLETE | 65 / 82 refs |
| **Phase 2: LLM Analysis** | ⏳ PENDING | 0 / 65 refs |
| **Phase 3: Holon Extraction** | ⏳ PENDING | 0 refs |
| **Phase 4: Integration** | ⏳ PENDING | - |

---

## Metadata Schema

Each `metadata/REF-XXX.json` follows `library_schema.json`:

```json
{
  "ref_id": "REF-001",
  "title": "Diagonal arguments and Cartesian closed categories",
  "authors": ["Lawvere"],
  "year": 1969,
  "source_type": "paper",
  "category": "I.1 Category Theory",
  "original_file": "pdf/REF-001_Lawvere_1969.pdf",
  "enhanced_txt": "txt/REF-001.txt",
  "images_dir": "images/REF-001/",
  "page_count": 10,
  "image_count": 5,
  "token_count_estimate": 7613,

  "summary": "[TO BE GENERATED BY LLM]",
  "smoc_relevance_summary": "[TO BE GENERATED BY LLM]",
  "key_smoc_concepts": [],
  "important_figures": [],
  "important_equations": [],
  "cross_references": [],
  "gaps_or_extensions": "[TO BE GENERATED BY LLM]",
  "priority_tier": null
}
```

Fields marked `[TO BE GENERATED BY LLM]` await analysis (see Phase 2 below).

---

## Next Steps

### Phase 2: LLM Analysis (Manual Process)

For each priority reference:

```bash
# 1. Generate analysis prompt
python3 analyze_ref.py REF-001

# 2. Review the prompt
cat metadata/REF-001_analysis_prompt.txt

# 3. Feed to LLM (Gemini 2.5 Pro recommended, 2M context)
# Copy prompt, send to Gemini, get JSON response

# 4. Save JSON response to metadata/REF-001_analysis.json

# 5. Merge into metadata (TODO: write merge_analysis.py)
python3 merge_analysis.py REF-001

# 6. Inject relevance into TXT (TODO: write inject_relevance.py)
python3 inject_relevance.py REF-001

# 7. Validate
python3 validate_metadata.py REF-001
```

**Priority Tier 1 (Analyze first):**
- REF-001 (Lawvere - proves CODOME/CONTEXTOME)
- REF-040 (Friston - free energy = purpose field)
- KOESTLER-1967 (holons, 16-level hierarchy)
- REF-081 (Simon - near-decomposability)
- REF-088 (Gentner - structure-mapping)

### Phase 3: Holon Hierarchy Extraction

For references with explicit hierarchies:

```bash
python3 extract_holons.py KOESTLER-1967 --output metadata/HOL-KOESTLER-1967.json
```

Validates against `holon_hierarchy_schema.json`.

### Phase 4: Integration with ./pe

Add commands:
```bash
./pe refs list                 # Show catalog
./pe refs show REF-001         # Display metadata
./pe refs read REF-001         # Open TXT
./pe refs analyze REF-001      # Trigger LLM analysis
./pe refs validate             # Validate all schemas
```

---

## Validation

Run after Phase 2 completes:

```bash
python3 validate_metadata.py --all
```

Checks:
- Schema compliance (`library_schema.json`)
- All image paths exist
- Cross-references resolve
- TXT files have filled SMoC sections
- No stub placeholders remain

---

## Tools

| Script | Purpose |
|--------|---------|
| `process_library.py` | Extract images + TXT from PDFs (Phase 1) |
| `analyze_ref.py` | Generate LLM analysis prompts (Phase 2) |
| `merge_analysis.py` | Merge LLM JSON into metadata (TODO) |
| `inject_relevance.py` | Insert SMoC sections into TXT (TODO) |
| `validate_metadata.py` | Schema validator (TODO) |
| `extract_holons.py` | Generate holon hierarchies (TODO) |
| `monitor_analysis.py` | Background job monitor (TODO) |

---

## Search

```bash
# Search by term
cat index/catalog.json | jq '.references[] | select(.title | contains("Category"))'

# By author
cat index/catalog.json | jq '.by_author["Friston"]'

# By year
cat index/catalog.json | jq '.by_year["2010"]'

# Find specific concept (after analysis complete)
cat metadata/*.json | jq 'select(.key_smoc_concepts[].smoc_concept == "free_energy_minimization")'
```

---

## Contributing

To add a new reference:

1. Download PDF to `pdf/REF-XXX_Author_Year_Title.pdf`
2. Run: `python3 process_library.py` (re-processes all)
3. Or manually: `python3 analyze_ref.py REF-XXX` then follow Phase 2 steps

---

*For full integration plan, see `VALIDATION_AND_INTEGRATION_PLAN.md`*
