{
  "_meta": {
    "saved_at": "2026-01-23T14:14:10.310535",
    "source": "gemini",
    "model": "gemini-3-pro-preview",
    "query": "We have established workflow standards for AI agents:\n\n1. At 85%+ confidence, tasks MUST have full step decomposition (TASK-XXX-S01, S02...)\n2. Every session end MUST have path forward priority matrix with confidence scores\n3. 4D confidence (factual/alignment/current/onwards) must be verified with evidence\n4. Never stop without recommendations\n\nPROBLEM: These standards exist in docs (AGENT_KERNEL.md, DOD.md, CLAUDE.md) but agents don't consistently follow them.\n\nQUESTION: How do we make these standards PERSISTENT and SEAMLESSLY INTEGRATED into the workflow? Options:\n1. Pre-commit hooks that validate task files?\n2. A gate in promote_opportunity.py that requires step count at 85%+?\n3. A post-session validator that checks for path forward?\n4. Integration with boost_confidence.py?\n\nRecommend the best approach with implementation steps.",
    "query_length": 843,
    "checksum": "sha256:410e5a574669babec8a30b313637095bf9df181c6af80b9f5b87b8c868d9e8e0"
  },
  "response": {
    "content": "Based on the codebase context and the \"Alien Architecture\" philosophy (Body vs. Brain), relying on the agent's memory or willingness to read `DOD.md` is insufficient. Agents suffer from context myopia.\n\nTo make these standards persistent, you must move enforcement from **Passive Documentation** (text files) to **Active Tooling** (scripts that refuse to proceed without compliance).\n\nI recommend a **Hybrid Tooling Approach** focused on two specific interaction points: **The Promotion Gate** (Start) and **The Exit Protocol** (End).\n\nHere is the implementation plan.\n\n### 1. The Strategy: \"Tool-Enforced Workflow\"\n\nInstead of asking the agent to *remember* to decompose tasks or write matrices, we update the tools so the agent *cannot* proceed without doing so.\n\n| Requirement | Implementation Point | Mechanism |\n| :--- | :--- | :--- |\n| **1. Step Decomposition** | `promote_opportunity.py` | **Hard Gate**: Script raises error if `confidence > 85` and `subtasks < 2`. |\n| **2. Path Forward Matrix** | `finish_session.py` (New) | **Generator**: Interactive script prompts agent for rows, generates MD table. |\n| **3. 4D Verification** | `boost_confidence.py` | **Validator**: Script requires file citations for every score increase. |\n| **4. Recommendations** | `finish_session.py` | **Mandatory Field**: Script prompts for \"Next Actions\". |\n\n---\n\n### 2. Implementation Steps\n\n#### Step A: Modify `promote_opportunity.py` (The Entry Gate)\n*Loc: `context-management/tools/agent/promote_opportunity.py` (assumed path)*\n\nAdd logic to enforce the 85% rule physically.\n\n```python\n# Pseudo-code implementation logic\ndef promote_task(task_id, confidence_score):\n    # Load task data\n    task = load_task(task_id)\n    \n    # REQUIREMENT 1: Decompisition Enforcement\n    if confidence_score >= 85:\n        subtasks = task.get('subtasks', [])\n        if not subtasks:\n            raise WorkflowViolationError(\n                f\"‚õî BLOCKED: Task {task_id} has High Confidence ({confidence_score}%). \"\n                \"The Standard Model requires explicit step decomposition (S01, S02...) \"\n                \"before promotion. Please define execution steps.\"\n            )\n            \n    # ... proceed with promotion\n```\n\n#### Step B: Create `finish_session.py` (The Exit Protocol)\n*Loc: `context-management/tools/agent/finish_session.py`*\n\nDon't ask the agent to write the \"Path Forward\" matrix. Give them a tool that generates it. This ensures standard compliance and reduces hallucination.\n\n```python\n#!/usr/bin/env python3\nimport sys\nimport json\n\ndef main():\n    print(\"üõë SESSION EXIT PROTOCOL INITIATED\")\n    print(\"-----------------------------------\")\n    \n    # 1. Enforce Path Forward\n    print(\"Generating Path Forward Matrix...\")\n    matrix_items = []\n    while True:\n        action = input(\"Next Action (or 'done'): \")\n        if action == 'done': break\n        priority = input(\"Priority (P0-P3): \")\n        confidence = input(\"Confidence (0-100%): \")\n        matrix_items.append({\"p\": priority, \"a\": action, \"c\": confidence})\n    \n    if not matrix_items:\n        print(\"‚ùå ERROR: You cannot stop without a Path Forward.\")\n        sys.exit(1)\n\n    # 2. Enforce Recommendations\n    recs = input(\"Recommendations for next session: \")\n    if len(recs) < 10:\n        print(\"‚ùå ERROR: Detailed recommendations required.\")\n        sys.exit(1)\n\n    # Generate the Markdown Output\n    print(\"\\n‚úÖ SESSION WRAP-UP (Copy this to output):\")\n    print(\"\\n## Path Forward\")\n    print(\"| Priority | Next Action | Confidence |\")\n    print(\"|----------|-------------|------------|\")\n    for i in matrix_items:\n        print(f\"| {i['p']} | {i['a']} | {i['c']}% |\")\n    \n    print(f\"\\n### Recommendations\\n{recs}\")\n    \n    # 3. Clean Git Check\n    # (Insert logic to check git status here and warn if dirty)\n\nif __name__ == \"__main__\":\n    main()\n```\n\n#### Step C: Update `aci_config.yaml` (The Context Trigger)\n*Loc: `context-management/config/aci_config.yaml`*\n\nAdd a trigger so that when an agent attempts to wrap up, ACI injects the instruction to use the tool.\n\n```yaml\n# ... existing config ...\n\nagent_context:\n  trigger_keywords:\n    # ... existing keywords ...\n    - \"done\"\n    - \"finish\"\n    - \"wrap up\"\n    - \"complete\"\n    - \"summary\"\n\n  levels:\n    # ... existing levels ...\n    \n    # NEW: Enforce the exit protocol\n    workflow_enforcer:\n      sets: [\"agent_kernel\"]\n      description: \"Workflow compliance injection\"\n      static_injection: |\n        üõë STOP. Do not write a manual summary.\n        \n        To complete this session, you MUST run:\n        `python context-management/tools/agent/finish_session.py`\n        \n        This tool will generate the required Path Forward Matrix and Recommendations \n        to satisfy the Definition of Done.\n```\n\n### 3. Workflow Integration\n\nOnce implemented, the workflow becomes:\n\n1.  **Agent starts task**: Runs `promote_opportunity.py`.\n    *   *Result:* Script fails if they haven't decomposed a high-confidence task. Agent is forced to decompose.\n2.  **Agent works**: Reads/Writes code.\n3.  **Agent tries to finish**: Says \"I am done, here is the summary...\"\n4.  **ACI Intervenes**: Injects the prompt: \"üõë STOP. Run `finish_session.py`.\"\n5.  **Agent runs tool**: The tool prompts for the matrix data and prints the standardized markdown.\n6.  **Agent outputs tool result**: Perfect compliance is achieved programmatically.\n\n### 4. Recommendation\n\n**Go with Option 5 (Hybrid Tooling).**\n\n*   **Pre-commit hooks** are too late (frustrating) and too dumb (can't validate semantic intent).\n*   **Validators** are passive.\n*   **Tooling (Scripts)** is active. Agents prefer using tools to writing boilerplate.\n\n**Immediate Action:**\n1.  Create `context-management/tools/agent/finish_session.py`.\n2.  Update `aci_config.yaml` to scream at the agent if they try to exit without running it.",
    "mode": "standard"
  }
}