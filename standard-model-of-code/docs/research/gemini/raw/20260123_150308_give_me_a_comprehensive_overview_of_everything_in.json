{
  "_meta": {
    "saved_at": "2026-01-23T15:03:08.316044",
    "source": "gemini",
    "model": "gemini-3-pro-preview",
    "query": "Give me a comprehensive overview of everything in the project - what are the main components and how do they fit together?",
    "query_length": 122,
    "checksum": "sha256:f30d1ba188f54890200a13ca3477a3964e67d4f39ebf73d7235254ca38ed7245"
  },
  "response": {
    "content": "This project, **PROJECT_elements**, is an ambitious engineering effort to create a \"Standard Model of Code\"â€”treating software not as text, but as a physics-like system composed of fundamental particles (\"Atoms\") with specific properties (\"Dimensions\").\n\nThe architecture is strictly divided into two \"Hemispheres\": **The Body** (The Engine) and **The Brain** (The Intelligence).\n\n---\n\n### 1. The Architecture: Two Hemispheres\n\nThe repository is split physically and conceptually:\n\n| Hemisphere | Directory | Purpose | Key Artifact |\n| :--- | :--- | :--- | :--- |\n| **THE BODY** | `standard-model-of-code/` | **The Physics Engine.** It parses source code, identifies \"Atoms,\" classifies them, and builds a dependency graph. It creates the \"truth.\" | `Collider` (CLI Tool) |\n| **THE BRAIN** | `context-management/` | **The Intelligence Layer.** It manages AI context, runs automated audits, facilitates queries, and mirrors data to the cloud. It *uses* the truth. | `analyze.py` (AI Interface) |\n\n---\n\n### 2. The Body: `standard-model-of-code` (The Collider)\n\nThis is the core analysis engine. Its job is to ingest raw source code and output a semantic graph.\n\n**The Theory (The Map):**\n*   **16 Levels:** Code exists on a scale from L-3 (Bits) to L12 (Universe/All Code). The engine focuses on **L3 (The Node/Function)**.\n*   **The Octahedral Atom:** Every piece of code (function, class, method) is classified along **8 Dimensions** (e.g., Role, Layer, State, Effect, Boundary).\n*   **200 Atoms:** A periodic table of code elements (e.g., `LOG.FNC` for Function, `DAT.VAR` for Variable).\n\n**The Tool (The Collider):**\nThe `collider` CLI tool runs a multi-stage pipeline:\n1.  **Parsing:** Uses `tree-sitter` to turn code into an Abstract Syntax Tree (AST).\n2.  **Extraction:** Converts AST nodes into \"Particles.\"\n3.  **Classification:** Assigns Roles (e.g., Repository, Service) and Atoms to particles using regex patterns and heuristics.\n4.  **Enrichment:** Calculates the 8 Dimensions (e.g., is this `Pure`? Is it `Stateful`?).\n5.  **Graphing:** Connects particles via edges (Calls, Imports, Inherits).\n6.  **Output:** Generates `unified_analysis.json` (the raw data) and `output.html` (a 3D visualization).\n\n---\n\n### 3. The Brain: `context-management` (The Intelligence)\n\nThis layer sits on top of the data generated by the Body. It orchestrates how AI agents and developers interact with the codebase.\n\n**Key Systems:**\n\n*   **ACI (Adaptive Context Intelligence):**\n    *   A \"Curriculum Compiler\" for AI. When you ask a question, it doesn't just dump files into the context window.\n    *   It uses a **Tiered System**:\n        *   **Tier 0 (Instant):** Uses cached \"Truths\" (e.g., \"How many files?\").\n        *   **Tier 1 (RAG):** Fast file search for specific lookups.\n        *   **Tier 2 (Long Context):** Loads deep context for architectural reasoning.\n    *   It manages token budgets and strategically positions critical files (the \"Sandwich Strategy\") to prevent the LLM from forgetting instructions.\n\n*   **The Triad (AI Personas):**\n    *   **The Librarian:** Uses Vector Search (RAG) to find needles in haystacks.\n    *   **The Surgeon:** Uses `analyze.py --mode forensic` to provide line-level citations.\n    *   **The Architect:** Uses `analyze.py --mode architect` to reason about system topology against the Standard Model theory.\n\n*   **HSL (Holographic-Socratic Layer):**\n    *   An automated \"immune system\" that runs continuously (via `analyze.py --verify`).\n    *   It audits the code against \"Antimatter Laws\" (e.g., \"Controllers cannot import Repositories directly\").\n\n*   **The Mirror:**\n    *   A system (`tools/archive/archive.py`) that syncs the codebase state to Google Cloud Storage, allowing cloud-based AI agents to access the latest version of the repo.\n\n---\n\n### 4. The Data Flow\n\n```mermaid\ngraph TD\n    SourceCode[Source Code] -->|Tree-Sitter| Body[The Body: Collider]\n    Body -->|Pipeline| Graph[Unified Graph JSON]\n    \n    Graph -->|Input| Brain[The Brain: Context Management]\n    \n    Brain -->|ACI| Context[Optimized Context Window]\n    Brain -->|HSL| Alerts[Violation Reports]\n    Brain -->|Mirror| Cloud[GCP Bucket]\n    \n    Context --> AI[AI Agent / LLM]\n    AI -->|Response| User\n```\n\n### 5. Key Operational Files\n\nIf you are working in this repo, these are your primary interfaces:\n\n*   **`context-management/tools/ai/analyze.py`**: The \"Swiss Army Knife\" for querying the codebase.\n    *   `python analyze.py \"Explain the architecture\"` (Uses ACI)\n    *   `python analyze.py --verify pipeline` (Runs HSL audit)\n*   **`standard-model-of-code/cli.py`**: The entry point for the analysis engine.\n    *   `./collider full src/core` (Runs the full analysis pipeline)\n*   **`context-management/config/analysis_sets.yaml`**: Defines \"views\" of the codebase (e.g., `pipeline`, `theory`) that ACI loads for specific query types.\n*   **`context-management/docs/agent_school/`**: Contains the rules of engagement (`DOD.md`, `WORKFLOWS.md`) for AI agents.\n\n### Summary\n\nYou are building a system that turns **code (text)** into **physics (graphs)** so that **AI (Brain)** can reason about it like an **engineer**, rather than just predicting tokens like a chatbot.",
    "mode": "standard"
  }
}