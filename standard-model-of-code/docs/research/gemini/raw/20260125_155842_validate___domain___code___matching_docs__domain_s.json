{
  "_meta": {
    "saved_at": "2026-01-25T15:58:42.141150",
    "source": "gemini",
    "model": "gemini-3-pro-preview",
    "query": "Validate: 'Domain = code + matching docs. Domain Symmetry measures if code matches its docs.'\n\nDoes the codebase show this pattern? Examples: full_analysis.py + PIPELINE_STAGES.md, modules/*.js + UI_SPEC.md\n\nScore 0-100 for accuracy and usefulness.",
    "query_length": 248,
    "checksum": "sha256:9990a3b59fd56dcf6603c20ead9ff6fee30c5df4a6f6739645c0bd09aac010eb"
  },
  "response": {
    "content": "Based on the analysis of the provided codebase, here is the validation of the proposition: **'Domain = code + matching docs. Domain Symmetry measures if code matches its docs.'**\n\n### Validation Analysis\n\nThe codebase **strongly supports** the philosophy of \"Domain Symmetry,\" though the implementation differs slightly from a literal \"parse markdown vs. parse code\" comparison. Instead, the \"Docs/Spec\" are internalized as rigid schemas, taxonomies, and architectural rules within the classifier logic. The system acts as a validator that the \"Code\" matches the \"Standard Model\" (the implied Domain).\n\n#### 1. Evidence of Domain Symmetry (Code matching \"Specs\")\n\n**A. Path-to-Structure Symmetry (The \"Location Spec\")**\nIn `universal_classifier.py`, the code enforces that file location (the directory structure/docs) must match the code behavior. This is a direct measure of symmetry between \"Where it says it is\" and \"What it actually does.\"\n\n*   **Code:** `universal_classifier.py` (Lines 111-135, 237-285)\n*   **Mechanism:** It explicitly checks if files inside `/domain/entities/` actually act like entities, or if files in `/presentation/` act like Controllers.\n*   **Symmetry Check:** If a class is in `/infrastructure/` but contains business logic (detected via imports or body analysis), the `confidence` score likely drops or the classification shifts, indicating a break in symmetry.\n\n**B. Naming-to-Behavior Symmetry (The \"Vocabulary Spec\")**\nIn `heuristic_classifier.py`, the code enforces that the *name* of a component (its label/doc) matches its *pattern* (its behavior).\n\n*   **Code:** `heuristic_classifier.py`\n*   **Mechanism:** It calculates `confidence` scores. For example, if a function is named `create_user` (implies Factory/Command) but the body doesn't match the pattern (low confidence), the symmetry is broken.\n*   **Evidence:** The `MISSING_CANONICAL_ROLES` (Line 29) act as the \"Documentation Standard\" that the code is measured against.\n\n**C. The Pipeline as Code (Matching `PIPELINE_STAGES.md`)**\nYou requested a specific example regarding `full_analysis.py` + `PIPELINE_STAGES.md`. The file `universal_detector.py` serves as this `full_analysis.py`.\n\n*   **Code:** `universal_detector.py` -> `UniversalPatternDetector.analyze_repository`\n*   **Symmetry:** The code is structured in explicit steps (Step 1, Step 1.5, Step 2...) that mirror a documentation artifact.\n    *   *Step 1:* `tree_sitter_engine.analyze_directory`\n    *   *Step 2:* `particle_classifier` (Quarantined)\n    *   *Step 3:* `stats_generator`\n    *   *Step 3.5:* `god_class_detector`\n*   **Observation:** The code *is* the executable specification of the pipeline.\n\n**D. Code-to-Ecosystem Symmetry**\nIn `universal_classifier.py` (Line 414), the code checks `dims[\"D1_ECOSYSTEM\"]`.\n*   **Mechanism:** It reads imports (documentation of dependencies) to determine if the code matches a specific ecosystem (e.g., React, Django, Torch). This verifies that the code \"speaks the language\" it claims to import.\n\n#### 2. Gap Analysis (Literal vs. Architectural)\n\n*   **Literal Interpretation:** The codebase does **not** contain a module that opens `UI_SPEC.md`, parses natural language requirements, and compares them to `modules/ui.js`.\n*   **Architectural Interpretation:** The codebase **does** contain `ddd_mappings.py` and `role_registry.py` (imported). These files serve as the \"Canonical Documentation.\" The `UniversalDetector` measures how well the target repository adheres to this \"Canonical Doc.\"\n\n### Scoring\n\n**Accuracy: 85/100**\n*   *Why:* The codebase accurately implements the *spirit* of Domain Symmetry (checking code against a rigid definition of domain roles and architectural layers). It falls short of 100 because it compares code against *internalized rules* (Python classes/Dictionaries) rather than external Documentation/Markdown files, which is implied by \"matching docs.\"\n\n**Usefulness: 98/100**\n*   *Why:* This pattern is incredibly useful. By treating the \"Standard Model of Code\" (the classification rules) as the \"Doc,\" the system can automatically grade *any* codebase on how well it adheres to standard architectural patterns (Clean Architecture, DDD). It turns \"Code Review\" into a computable metric (`confidence`, `D8_TRUST`, `GodClass` detection).\n\n### Conclusion\n\nThe codebase validates the proposition **\"Domain = code + matching docs\"** by treating the **Classification Logic as the Living Documentation**.\n\n*   If `Code Structure` matches `UniversalClassifier Rules`, Symmetry is High (High Confidence).\n*   If `Code Structure` violates `UniversalClassifier Rules` (e.g., God Classes detected in `universal_detector.py`), Symmetry is Low (Antimatter detected).",
    "mode": "standard"
  }
}