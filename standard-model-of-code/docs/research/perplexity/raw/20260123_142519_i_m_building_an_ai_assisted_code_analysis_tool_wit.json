{
  "_meta": {
    "saved_at": "2026-01-23T14:25:19.087194",
    "source": "perplexity-mcp",
    "model": "sonar-pro",
    "query": "I'm building an AI-assisted code analysis tool with a multi-tier query routing system:\n\n- TIER 1 (RAG): Local file search with citations\n- TIER 2 (LONG_CONTEXT): Gemini with full local codebase context (up to 1M tokens)\n- TIER 3 (PERPLEXITY): External web research via Perplexity API\n\nCURRENT PROBLEM:\nWhen routing to Perplexity (Tier 3), the local codebase context is completely ignored. The raw user query goes directly to Perplexity. This means external research isn't grounded in our specific project context.\n\nPROPOSED FIX:\nBefore sending to Perplexity, generate a summary of relevant local context and prefix it to the query.\n\nQUESTIONS:\n\n1. What is the best practice for 'grounding' external LLM/search queries with local context? Is prefixing a summary the right approach, or are there better patterns?\n\n2. What should the context summary include for maximum relevance without exceeding Perplexity's input limits?\n   - Just key terms/entities?\n   - A structured brief (project name, domain, key concepts)?\n   - Relevant code snippets?\n\n3. Should the summary be generated by:\n   - A) Static template filled with metadata\n   - B) LLM-generated summary (Gemini summarizes context, then Perplexity researches)\n   - C) Hybrid (template + LLM refinement)\n\n4. Are there established patterns like 'Retrieval-Augmented Research' or 'Grounded Web Search' that address this?\n\n5. What's the optimal summary length for Perplexity's sonar-pro model to maintain relevance without noise?\n\nProvide concrete recommendations with rationale.",
    "query_length": 1529,
    "checksum": "sha256:5ca4bb7a60e29c3859fa1a012a33fc7fd5d54cffb80644c9120b5d89e6cb1d17"
  },
  "response": {
    "id": "5a65926a-8666-4475-b642-045f7a7e89df",
    "model": "sonar-pro",
    "created": 1769189119,
    "usage": {
      "prompt_tokens": 343,
      "completion_tokens": 1213,
      "total_tokens": 1556,
      "search_context_size": "low",
      "cost": {
        "input_tokens_cost": 0.001,
        "output_tokens_cost": 0.018,
        "request_cost": 0.006,
        "total_cost": 0.025
      }
    },
    "citations": [
      "https://www.moveworks.com/us/en/resources/blog/what-is-grounding-ai",
      "https://github.com/pgalko/BambooAI/wiki/Grounding-Data-Analysis-with-Domain%E2%80%90Specific-Ontologies",
      "https://sourcegraph.com/blog/lessons-from-building-ai-coding-assistants-context-retrieval-and-evaluation",
      "https://dev.to/get_pieces/how-context-grounding-ai-decreases-hallucinations-3p8a",
      "https://insights.daffodilsw.com/blog/vibe-coding-isnt-enough-how-to-build-context-aware-systems-with-ai",
      "https://www.anthropic.com/engineering/effective-context-engineering-for-ai-agents",
      "https://www.elastic.co/what-is/context-engineering",
      "https://www.salesforce.com/blog/what-is-grounding/",
      "https://redmonk.com/videos/context-engineering-in-practice-how-atlassian-is-building-ai-for-real-developer-work-with-kun-chen/"
    ],
    "search_results": [
      {
        "title": "Grounding AI: Improving AI Context Relevance - Moveworks",
        "url": "https://www.moveworks.com/us/en/resources/blog/what-is-grounding-ai",
        "date": "2023-07-27",
        "last_updated": "2026-01-23",
        "snippet": "Grounding AI links abstract knowledge to real-world examples, enhancing context-awareness, accuracy, and enabling models to excel in complex ...",
        "source": "web"
      },
      {
        "title": "Grounding Data Analysis with Domain‐Specific Ontologies - GitHub",
        "url": "https://github.com/pgalko/BambooAI/wiki/Grounding-Data-Analysis-with-Domain%E2%80%90Specific-Ontologies",
        "date": "2025-05-18",
        "last_updated": "2025-08-26",
        "snippet": "Objective: To significantly enhance the accuracy, reliability, and domain-relevance of AI-driven data analysis by grounding Large Language ...",
        "source": "web"
      },
      {
        "title": "Lessons from Building AI Coding Assistants: Context Retrieval and ...",
        "url": "https://sourcegraph.com/blog/lessons-from-building-ai-coding-assistants-context-retrieval-and-evaluation",
        "date": "2025-02-20",
        "last_updated": "2026-01-23",
        "snippet": "Any AI coding assistant should be able to provide highly relevant, contextual answers that are grounded in your codebase. Simply put, without ...",
        "source": "web"
      },
      {
        "title": "How Context Grounding AI Decreases Hallucinations",
        "url": "https://dev.to/get_pieces/how-context-grounding-ai-decreases-hallucinations-3p8a",
        "date": "2024-08-05",
        "last_updated": "2025-09-11",
        "snippet": "Grounding AI models connects abstract representations of words to reality, which can decrease hallucinations (wrong outputs) and increase ...",
        "source": "web"
      },
      {
        "title": "Vibe Coding Isn't Enough: How to Build Context-Aware Systems with ...",
        "url": "https://insights.daffodilsw.com/blog/vibe-coding-isnt-enough-how-to-build-context-aware-systems-with-ai",
        "date": "2025-12-30",
        "last_updated": "2026-01-22",
        "snippet": "This blog is about how vibe coding alone falls short in production systems, and why context-aware AI, with strong governance and ...",
        "source": "web"
      },
      {
        "title": "Effective context engineering for AI agents - Anthropic",
        "url": "https://www.anthropic.com/engineering/effective-context-engineering-for-ai-agents",
        "date": "2025-09-29",
        "last_updated": "2026-01-23",
        "snippet": "To enable agents to work effectively across extended time horizons, we've developed a few techniques that address these context pollution ...",
        "source": "web"
      },
      {
        "title": "What is Context Engineering? Architecting Reliable AI - Elastic",
        "url": "https://www.elastic.co/what-is/context-engineering",
        "date": "2025-11-08",
        "last_updated": "2026-01-23",
        "snippet": "Context engineering is the practice of giving AI systems the right information at the right time. Think of it like preparing a briefing for a new colleague: ...",
        "source": "web"
      },
      {
        "title": "What is prompt grounding? — A generative AI tutorial - Salesforce",
        "url": "https://www.salesforce.com/blog/what-is-grounding/",
        "date": "2024-07-03",
        "last_updated": "2026-01-23",
        "snippet": "The simplest way to ground an LLM prompt is by copying and pasting relevant data directly into the prompt's context window.",
        "source": "web"
      },
      {
        "title": "Context Engineering in Practice: How Atlassian Is Building AI for ...",
        "url": "https://redmonk.com/videos/context-engineering-in-practice-how-atlassian-is-building-ai-for-real-developer-work-with-kun-chen/",
        "date": "2025-12-18",
        "last_updated": "2026-01-23",
        "snippet": "Drawing on Atlassian's internal experience building Rovo Dev, Kun explains how AI agents become genuinely useful when they are grounded in the ...",
        "source": "web"
      }
    ],
    "object": "chat.completion",
    "choices": [
      {
        "index": 0,
        "message": {
          "role": "assistant",
          "content": "# Grounding External Search with Local Context\n\nYour proposed fix aligns with established best practices. **Prefixing a context summary before external search queries is a valid and widely-used grounding pattern**, though the specific content and generation method should be carefully considered for your use case.\n\n## Best Practices for Grounding External Queries\n\n**Context prefixing is the right foundational approach.** The principle of grounding—linking abstract knowledge to real-world specifics—applies equally to external searches as to local analysis[1]. When you prefix local context to a Perplexity query, you're implementing what amounts to **prompt grounding with external knowledge bases**, similar to how systems augment LLM prompts with semantic search results[1].\n\nHowever, research shows that effectiveness depends heavily on *what* context you include and *how* it's structured. Raw context injection has diminishing returns; systems that selectively extract task-relevant information significantly outperform those that include comprehensive but unfocused context[2]. The goal is to avoid \"context pollution\"—providing so much background that the external system struggles to identify what's actually relevant[6].\n\n## Optimal Context Summary Composition\n\nFor maximum relevance without noise, your summary should follow a **structured brief format with selective code references**:\n\n| Element | Inclusion | Rationale |\n|---------|-----------|-----------|\n| Project domain/purpose | Always | Helps Perplexity interpret the use case correctly[1] |\n| Key architectural concepts | Always | Frames the problem within your system's paradigm[5] |\n| Relevant technical constraints | Always | Prevents generic solutions misaligned with your stack[2] |\n| Specific code snippets | Selectively | Include only 1-3 representative examples (50-100 lines total) when they directly illustrate the problem[1] |\n| Full API/function signatures | Yes | Critical for getting accurate external recommendations[1] |\n| Metadata (framework versions, dependencies) | Conditionally | Only if directly relevant to the query[2] |\n\n**Avoid:** Entire file listings, extensive architectural documentation, or historical context unrelated to the specific question.\n\n**Structure it as:** A brief YAML or markdown block at the query prefix containing: project context, domain, key constraints, and 1-2 focused code examples[2].\n\nExample format:\n```\n---context---\nPROJECT: Analytics Pipeline (Python/PySpark)\nDOMAIN: Real-time data processing for financial markets\nKEY_CONSTRAINT: Sub-100ms latency requirement\nSTACK: PySpark 3.x, Delta Lake, Kafka\n\nRELEVANT_CODE:\n[1-2 representative snippets showing the actual problem area]\n---/context---\n\n[User's actual query to Perplexity]\n```\n\n## Recommended Generation Method: Hybrid Approach (Option C)\n\n**Use a hybrid strategy: LLM-refined template.** Here's why:\n\n1. **Start with a static template** populated from your codebase metadata (framework, key modules, constraints)[1]. This is fast and prevents hallucination.\n\n2. **Have Gemini refine it** specifically for the current query. Gemini should:\n   - Extract only the context relevant to the user's question (not all project context)[2]\n   - Identify the 1-2 most illustrative code snippets if applicable\n   - Compress domain-specific terminology into Perplexity-friendly explanations\n\n3. **Why not pure LLM generation?** LLMs can hallucinate context details when generating from scratch. A template keeps the foundation grounded in actual project metadata[2][4].\n\nThis hybrid approach balances **reduced hallucinations** (via templating) with **task-specific relevance** (via LLM refinement)[2].\n\n## Established Patterns\n\nThe pattern you're describing already exists in literature, though it's not universally standardized by a single name:\n\n- **Retrieval-Augmented Generation (RAG)** with external sources[1]: Your Tier 3 + context summary is essentially RAG applied to web search.\n- **Context Engineering** (Anthropic's framing)[6]: Giving AI systems \"the right information at the right time\"—directly applicable to your multi-tier system.\n- **Sensorimotor + Symbolic Grounding** (academic framing)[4]: Connecting abstract queries to concrete local system knowledge.\n\nAtlassian's approach with Rovo Dev and similar developer tools use this exact pattern: local codebase grounding before external reasoning[9].\n\n## Optimal Summary Length for Perplexity Sonar-Pro\n\n**Target 300-600 tokens for the context prefix; keep the actual query concise.**\n\nRationale:\n- Sonar-Pro has effectively unlimited context, so token limits aren't the constraint[6]\n- But **relevance degrades with verbose prefixes**—models show reduced precision for information retrieval when context is diluted[6]\n- A tight, structured 300-600 token summary maintains signal-to-noise ratio\n- This leaves ample room for Perplexity's web search reasoning without competing information\n\n**If the context summary would exceed 800 tokens, you're likely over-sharing.** Re-evaluate whether each piece is truly necessary for the query.\n\n## Concrete Implementation Recommendation\n\n1. **Create a context extractor** that generates the hybrid summary:\n   - Template layer: project metadata + relevant constraints (static, fast)\n   - Gemini refinement: filter template for query relevance + select code examples (10-20s latency)\n\n2. **Prefix the summary** to every Perplexity query from Tier 3\n\n3. **Include a marker** (like `---context---`) to help Perplexity distinguish context from the actual question\n\n4. **A/B test** two variants:\n   - Minimal context (just domain + key constraints)\n   - Rich context (+ code examples)\n\nMeasure whether external research recommendations are actually more aligned with your codebase specifics with the context included.\n\nThis hybrid, structured approach directly addresses the \"context pollution\" problem that reduces AI agent effectiveness across extended interactions[6], while implementing the grounding principle at each tier of your pipeline."
        },
        "delta": {
          "role": "assistant",
          "content": ""
        },
        "finish_reason": "stop"
      }
    ]
  }
}